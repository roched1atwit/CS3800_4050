{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "COMP3800_4050_final.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "nlI7V7adDDfp",
        "H2B1_JLVDDgO"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjHBbTJBS1Q-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f1a1ea9f-1cb4-40fa-c12c-fa23eaa50565"
      },
      "source": [
        "#### Setting up Spark for colab space, code provided by Professor Othman\n",
        "\n",
        "import os\n",
        "#Install Java\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "#Set JAVA_HOME path variable in Linux\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "!update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n",
        "!java -version\n",
        "\n",
        "\n",
        "#Install Spark\n",
        "#download Spark file\n",
        "!wget -q http://apache.osuosl.org/spark/spark-2.4.6/spark-2.4.6-bin-hadoop2.7.tgz\n",
        "#extract the file\n",
        "!tar xf spark-2.4.6-bin-hadoop2.7.tgz\n",
        "#Set SPARK-HOME path variable in Linux\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.6-bin-hadoop2.7\"\n",
        "\n",
        "\n",
        "#install findspark package\n",
        "!pip install -q findspark"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"1.8.0_252\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_252-8u252-b09-1~18.04-b09)\n",
            "OpenJDK 64-Bit Server VM (build 25.252-b09, mixed mode)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSkvjp4EDDeY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afZ55q7XDDec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create entry points to spark\n",
        "try:\n",
        "    sc.stop()\n",
        "except:\n",
        "    pass\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SparkSession, SQLContext\n",
        "conf = SparkConf().setAppName(\"lecture10\").setMaster(\"local[*]\")\n",
        "sc=SparkContext(conf = conf)\n",
        "spark = SparkSession(sparkContext=sc)\n",
        "sqlContext = SQLContext(sc)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PM-f-XunDDef",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "126eb518-7e64-40c2-e318-1ffea7b077ea"
      },
      "source": [
        "spark"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://51f547fe2c0d:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v2.4.6</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>lecture10</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f9b8efdf438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzS2NeKItk9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import substring, lit, desc, col\n",
        "import pyspark.sql.functions as F"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNYXU2UxXRNC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_nibrs_csv(firstyear,lastyear,state_name,state_abbr, csv, my_schema):\n",
        "    url_base=\"https://raw.githubusercontent.com/roched1atwit/CS3800_4050/master/data/\"\n",
        "\n",
        "    print((\"reading in data for \" + state_name + \" - \" + csv + \"...\"))\n",
        "\n",
        "    df_list = []\n",
        "    for year in range(firstyear,lastyear+1):\n",
        "        url = url_base+state_name+'/'+state_abbr+'-'+str(year)\n",
        "        url_c = url + '/' + csv + '.csv'\n",
        "              \n",
        "        try:\n",
        "            temp_df = pd.read_csv(url_c, error_bad_lines=False)\n",
        "        except:\n",
        "            # there was a format change in 2016 where NIBRS_data became capitalized\n",
        "            url_c = url + '/' + csv.upper() + '.csv' \n",
        "            try:\n",
        "                temp_df = pd.read_csv(url_c, error_bad_lines=False)\n",
        "                temp_df.columns = map(str.lower, temp_df.columns)\n",
        "            except:\n",
        "                continue\n",
        "        \n",
        "        temp_df['state'] = state_abbr\n",
        "        temp_df['year'] = year\n",
        "        df_list.append(temp_df)\n",
        "\n",
        "    full_df = pd.concat(df_list)\n",
        "\n",
        "    full_df = full_df.astype({'ethnicity_id':'float64'})\n",
        "\n",
        "    spark_df = spark.createDataFrame(full_df,schema=my_schema)\n",
        "\n",
        "    return spark_df\n",
        "            \n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uh_M8DINVxxu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "circumstances_schema = StructType([ StructField(\"circumstances_id\", IntegerType(), True)\\\n",
        "\n",
        "                       ,StructField(\"circumstances_type\", StringType(), True)\\\n",
        "\n",
        "                       ,StructField(\"circumstances_code\", IntegerType(), True)\\\n",
        "\n",
        "                       ,StructField(\"circumstances_name\", StringType(), True)\\\n",
        "\n",
        "                       ,StructField(\"state\", StringType(), True)\\\n",
        "                       \n",
        "                       ,StructField(\"year\", IntegerType(), True)])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5C8sb-dybze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arrestee_schema = StructType([ StructField(\"arrestee_id\", IntegerType(), True)\\\n",
        "\n",
        "                       ,StructField(\"incident_id\", IntegerType(), True)\\\n",
        "\n",
        "                       ,StructField(\"arrestee_seq_num\", IntegerType(), True)\\\n",
        "\n",
        "                       ,StructField(\"arrest_num\", StringType(), True)\\\n",
        "\n",
        "                       ,StructField(\"arrest_date\", StringType(), True)\\\n",
        "                       \n",
        "                       ,StructField(\"arrest_type_id\", IntegerType(), True)\\\n",
        "                       \n",
        "                       ,StructField(\"multiple_indicator\", StringType(), True)\\\n",
        "                       \n",
        "                       ,StructField(\"offense_type_id\", IntegerType(), True)\\\n",
        "                       \n",
        "                       ,StructField(\"age_id\", IntegerType(), True)\\\n",
        "                       \n",
        "                       ,StructField(\"age_num\", DoubleType(), True)\\\n",
        "                       \n",
        "                       ,StructField(\"sex_code\", StringType(), True)\\\n",
        "                       \n",
        "                       ,StructField(\"race_id\", IntegerType(), True)\\\n",
        "                       \n",
        "                       ,StructField(\"ethnicity_id\", DoubleType(), True)\\\n",
        "                       \n",
        "                       ,StructField(\"resident_code\", StringType(), True)\\\n",
        "                       \n",
        "                       ,StructField(\"under_18_disposition_code\", StringType(), True)\\\n",
        "                       \n",
        "                       ,StructField(\"clearance_ind\", DoubleType(), True)\\\n",
        "                       \n",
        "                       ,StructField(\"ff_line_number\", DoubleType(), True)\\\n",
        "                       \n",
        "                       ,StructField(\"age_range_low_num\", DoubleType(), True)\\\n",
        "                       \n",
        "                       ,StructField(\"age_range_high_num\", DoubleType(), True)\\\n",
        "                       \n",
        "                       ,StructField(\"state\", StringType(), True)\\\n",
        "                       \n",
        "                       ,StructField(\"year\", IntegerType(), True)\\\n",
        "                       \n",
        "                       ,StructField(\"data_year\", DoubleType(), True)])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPzouEmiwq72",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NOTE: Uncomment additional readings of states when running locally\n",
        "\n",
        "#arrestee = read_nibrs_csv(1991,2018,'alabama','AL','nibrs_arrestee', arrestee_schema)\n",
        "#arrestee = arrestee.union(read_nibrs_csv(1991,2018,'arizona', 'AZ', 'nibrs_arrestee', arrestee_schema))\n",
        "#arrestee = arrestee.union(read_nibrs_csv(1991,2018,'arkansas', 'AR', 'nibrs_arrestee', arrestee_schema))\n",
        "#arrestee = arrestee.union(read_nibrs_csv(1991,2018,'colorado', 'CO', 'nibrs_arrestee', arrestee_schema))\n",
        "#arrestee = arrestee.union(read_nibrs_csv(1991,2018,'connecticut', 'CT', 'nibrs_arrestee', arrestee_schema))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73wNQulmCiPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#arrestee.show()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ltsWZ_486yW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# hardcoded variables telling our program which states, years, and tables are needed from NIBRS dataa\n",
        "\n",
        "# Can make the list longer if running locally, for google colab, better to do one state at a time\n",
        "\n",
        "state_list = [\"alabama\", \"arizona\", \"arkansas\",\"colorado\", \"connecticut\",\"massachusetts\",\"texas\"]\n",
        "state_abbr = [\"AL\", \"AZ\", \"AR\", \"CO\", \"CT\",\"MA\",\"TX\"]\n",
        "csv = \"nibrs_arrestee\"\n",
        "firstyear = 1991\n",
        "lastyear = 2018"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aBYfa4UF7JY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "c9b44bd0-3afc-4bd1-c0c5-fe98b8154fff"
      },
      "source": [
        "\n",
        "for state_i in range(0,len(state_list)):\n",
        "\n",
        "    arrestee = read_nibrs_csv(firstyear,lastyear,state_list[state_i],state_abbr[state_i],csv, arrestee_schema)\n",
        "    res = arrestee.select(\"offense_type_id\", \"year\",\"state\")\n",
        "\n",
        "    # get the count of each type of crime per state per year\n",
        "    off_types = res.groupby(res.offense_type_id, res.year, res.state).count()\n",
        "\n",
        "    # get the total number of arrests per year, per state\n",
        "    num_arrests = res.groupby(res.year, res.state).count()\n",
        "    num_arrests = num_arrests.select(col(\"year\"), col(\"state\"), col(\"count\").alias(\"total_arrests_that_year\"))\n",
        "    off_types = off_types.orderBy(desc(\"count\"))\n",
        "    off_types = off_types.select(\"offense_type_id\", \"year\", \"state\", col(\"count\").alias(\"num_arrests\"))\n",
        "    #off_types.show()\n",
        "    #num_arrests.show()\n",
        "    off_types = off_types.join(num_arrests, ((off_types.state == num_arrests.state) & (off_types.year == num_arrests.year)), \"inner\")\n",
        "    #off_types.show()\n",
        "\n",
        "    off_types = off_types.withColumn(\"perc_tot_arrests\", col(\"num_arrests\")/col(\"total_arrests_that_year\"))\n",
        "    offenses = off_types.select(\"*\").toPandas()\n",
        "    offenses = offenses.loc[:,~offenses.columns.duplicated()]\n",
        "\n",
        "    arrestee.unpersist(True)\n",
        "    #print(arrestee.count())\n",
        "    res.unpersist(True)\n",
        "    #print(res.count())\n",
        "    num_arrests.unpersist(True)\n",
        "    off_types.unpersist(True)\n",
        "    #spark.catalog.clearCache()    #google colab cannot handle large datasets; if run locally, comment out these lines\n",
        "\n",
        "    if state_i == 0:\n",
        "        all_offenses = offenses\n",
        "    else:\n",
        "        all_offenses = pd.concat([all_offenses, offenses])\n",
        "    \n",
        "    offenses.unpersist(True)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reading in data for alabama - nibrs_arrestee...\n",
            "reading in data for arizona - nibrs_arrestee...\n",
            "reading in data for arkansas - nibrs_arrestee...\n",
            "reading in data for colorado - nibrs_arrestee...\n",
            "reading in data for connecticut - nibrs_arrestee...\n",
            "reading in data for massachusetts - nibrs_arrestee...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-1f16c04873cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0moff_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moff_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"perc_tot_arrests\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"num_arrests\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"total_arrests_that_year\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0moffenses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moff_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"*\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0moffenses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moffenses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0moffenses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mtoPandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2154\u001b[0m         \u001b[0;31m# Below is toPandas without Arrow optimization.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2155\u001b[0;31m         \u001b[0mpdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2156\u001b[0m         \u001b[0mcolumn_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    533\u001b[0m         \"\"\"\n\u001b[1;32m    534\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
            "\u001b[0;32m/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAQeOPDV050u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_offenses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FAL_LYX1722",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_offenses = all_offenses[['offense_type_id','year','state','total_arrests_that_year']]\n",
        "shoplfiting_by_state = all_offenses.loc[all_offenses['offense_type_id'] == 23]\n",
        "murder_by_state =  all_offenses.loc[all_offenses['offense_type_id'] == 32]\n",
        "a_assault_by_state = all_offenses.loc[all_offenses['offense_type_id'] == 27]\n",
        "shoplfiting_by_state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5FqeRL4Znce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "victim_circumstances_schema = StructType([ StructField(\"victim_id\", IntegerType(), True)\\\n",
        "\n",
        "                       ,StructField(\"circumstances_id\", IntegerType(), True)\\\n",
        "\n",
        "                       ,StructField(\"justifiable_force_id\", DoubleType(), True)\\\n",
        "\n",
        "                       ,StructField(\"state\", StringType(), True)\\\n",
        "\n",
        "                       ,StructField(\"data_year\", DoubleType(), True)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwupLDIHcJ9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "victim_schema = StructType([ StructField(\"victim_id\", IntegerType(), True)\\\n",
        "\n",
        "                       ,StructField(\"incident_id\", IntegerType(), True)\\\n",
        "\n",
        "                       #,StructField(\"victim_seq_num\", IntegerType(), True)\\\n",
        "\n",
        "                       #,StructField(\"victim_type_id\", IntegerType(), True)\\\n",
        "\n",
        "                       #,StructField(\"assignment_type_id\", DoubleType(), True)\\\n",
        "\n",
        "                       #,StructField(\"activity_type_id\", DoubleType(), True)\\\n",
        "\n",
        "                       #,StructField(\"outside_agency_id\", DoubleType(), True)\\\n",
        "\n",
        "                       #,StructField(\"age_id\", DoubleType(), True)\\\n",
        "\n",
        "                       #,StructField(\"age_num\", DoubleType(), True)\\\n",
        "\n",
        "                       #,StructField(\"sex_code\", StringType(), True)\\\n",
        "                       \n",
        "                       ,StructField(\"race_id\", DoubleType(), True)\\\n",
        "                       \n",
        "                       ,StructField(\"ethnicity_id\", DoubleType(), True)\\\n",
        "                       \n",
        "                       #,StructField(\"resident_status_code\", StringType(), True)\\\n",
        "                       \n",
        "                       #,StructField(\"agency_data_year\", DoubleType(), True)\\\n",
        "                       \n",
        "                       #,StructField(\"ff_line_number\", DoubleType(), True)\\\n",
        "                       \n",
        "                       #,StructField(\"age_range_low_num\", DoubleType(), True)\\\n",
        "                       \n",
        "                       #,StructField(\"age_range_high_num\", DoubleType(), True)\\\n",
        "                       \n",
        "                       ,StructField(\"state\", StringType(), True)\\\n",
        "                       \n",
        "                       #,StructField(\"data_year\", DoubleType(), True)\\\n",
        "                       \n",
        "                       ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpEupELRwOcj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "races_schema = StructType([ StructField(\"race_id\", IntegerType(), True)\\\n",
        "\n",
        "                       #,StructField(\"race_code\", StringType(), True)\\\n",
        "\n",
        "                       ,StructField(\"race_desc\", StringType(), True)\\\n",
        "\n",
        "                       #,StructField(\"start_year\", DoubleType(), True)\\\n",
        "\n",
        "                       #,StructField(\"end_year\", DoubleType(), True)\\\n",
        "\n",
        "                       #,StructField(\"notes\", StringType(), True)\\\n",
        "\n",
        "                       #,StructField(\"state\", StringType(), True)\n",
        "\n",
        "                        ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdAyBBTaVSgv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}